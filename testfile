https://www.hackerearth.com/challenges/competitive/garden-nerd-data-science-competition/machine-learning/flower-recognition/

Original

method 2
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding="same", activation="relu", input_shape=[32, 32, 3]))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))
model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(units=1024, activation='relu'))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(units=256, activation='relu'))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(units=128, activation='relu'))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(units=10, activation='softmax'))


Best
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding="same", activation="relu", input_shape=[32, 32, 3]))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))
model.add(tf.keras.layers.Dropout(rate=0.2))
model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))
model.add(tf.keras.layers.Dropout(rate=0.2))
model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))
model.add(tf.keras.layers.Dropout(rate=0.2))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(units=256, activation='relu'))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(units=128, activation='relu'))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(units=10, activation='softmax'))




https://www.hackerearth.com/problem/approximate/save-hawkins-3d060dfa/

--------------------------------------------------------------------------------------------------

# -*- coding: utf-8 -*-
"""
Created on Tue Sep 10 11:52:10 2019

@author: j.sokhal
"""
#cd D:/HE_Challenge_data/

import numpy as np
from tensorflow.python.keras.applications.resnet50 import preprocess_input
from tensorflow.python.keras.preprocessing.image import load_img, img_to_array
from os.path import join

import pandas as pd

from IPython.display import Image, display
## reading CSV files for IDS
    
train = pd.read_csv('./data/train.csv')
test = pd.read_csv('./data/test.csv')

trainDir = './data/train/'  
testDir = './data/test/'
format = '.jpg'

trainIds = [join(trainDir,str(id)+format) for id in train['image_id']]


image_size = 500

def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):
    imgs = []
    n = len(trainIds)
    for i in list(range(0,n,100)):
        end = i + 100
        print(i);
        if(end > n):
            end = n
        img = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths[i:end]]
        imgs.append(img)
    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]
    img_array = np.array([img_to_array(img) for img in imgs])
    output = preprocess_input(img_array)
    return(output)

out = read_and_prep_images(trainIds[0:1000])

----------------------------------------------------------------------------------------------


model.compile(loss="sparse_categorical_crossentropy",
              optimizer="Adam", metrics=["sparse_categorical_accuracy"])
------------------------------------------------------------------------------------------------------------

# -*- coding: utf-8 -*-
"""
Created on Tue Sep 10 11:52:10 2019

@author: j.sokhal
"""
#cd D:/HE_Challenge_data/

import numpy as np
from tensorflow.python.keras.applications.resnet50 import preprocess_input
from tensorflow.python.keras.preprocessing.image import load_img, img_to_array
from os.path import join
from PIL import Image as pilImage
from io import BytesIO 
import io
import tensorflow as tf
import pandas as pd

from IPython.display import Image, display
## reading CSV files for IDS

dire = ""    
train = pd.read_csv('./data/train.csv')
test = pd.read_csv('./data/test.csv')

trainDir = './data/train/'  
testDir = './data/test/'
format = '.jpg'

trainIds = [join(trainDir,str(id)+format) for id in train['image_id']]
testIds = [join(testDir,str(id)+format) for id in test['image_id']]


image_size = 128



def read_Image_file(path,size=128):    
    with open(path, 'rb') as fin:
        #data = io.BytesIO(fin.read())
        interpolation=pilImage.NEAREST
        width_height_tuple = (size,size)
        ioFile = pilImage.open(BytesIO(fin.read()))
        resample = interpolation
        ioFile = ioFile.resize(width_height_tuple, resample)        
        fin.close()
    return ioFile
   
def getJpegList(paths):
    imgs = []
    n = len(paths)
    for i in list(range(0,n,100)):
        end = i + 100
        print(i)
        if(end > n):
            end = n
        [imgs.append(read_Image_file(img_path)) for img_path in paths[i:end]]
    return imgs

def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):
    #print(len(img_paths))
    imgs = getJpegList(img_paths)
    #imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]
    img_array = np.array([img_to_array(img) for img in imgs])
    output = preprocess_input(img_array)
    return(output)

trainData = read_and_prep_images(trainIds[0:10])
testData = read_and_prep_images(testIds[0:100])

trainData = trainData/255.0
testData = testData/255.0

y = np.array(train.iloc[:10,1])
y = y.reshape(y.shape[0],1)


model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding="same", activation="relu", input_shape=[image_size, image_size, 3]))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))
model.add(tf.keras.layers.Dropout(rate=0.2))
model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))
model.add(tf.keras.layers.Dropout(rate=0.2))
model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.BatchNormalization())
#model.add(tf.keras.layers.Conv2D(filters=1024, kernel_size=3, padding="same", activation="relu"))
#model.add(tf.keras.layers.BatchNormalization())
#model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))
#model.add(tf.keras.layers.Dropout(rate=0.2))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(units=256, activation='relu'))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(units=102, activation='softmax'))

model.compile(loss="sparse_categorical_crossentropy",
              optimizer="Adam", metrics=["sparse_categorical_accuracy"])



model.fit(trainData,y,epochs=5)


---------------------------------------------------------------------------------------------------------------
	
	public static long getAns(long n,long m){
		long max = (n*(n-1)/2L) + n;
		if(m < (n-1) || m > max) {
			return -1L;
		}
		else if(n==1) {
			if(m<=1) {
				return m;
			}
		}
		else if(n==2) {
			return 2L;
		}
		else if(m <= (n<<1)) {
			return 3L;
		}
		long degree = (m-n) << 1;
		long ans = (degree + n - 1L)/n;
		ans = ans + 1L;
		return ans;
    }
	public static void main (String[] args) throws java.lang.Exception
	{
		Scanner sc = new Scanner(System.in);
		int testCase = sc.nextInt();
		while(testCase-->0){
		    long n = sc.nextLong();
		    long m = sc.nextLong();
		    long ans = getAns(n,m);
		    System.out.println(ans);
		}
	}
-----------------------------------------------


	public static long mod = (long)Math.pow(10, 9) + 7L;
	
	public static int max = 20;
	
	public static long fib[] = new long[(max/2) + 1];
	
	static {
		preFib();
	}
	
	public static void preFib(){
		fib[0] = 1;
		fib[1] = 1;
		for(int i=2;i<fib.length;i++) {
			fib[i] = (((long)i) * fib[i-1])%mod;
		}
	}
	
	public static long comb(int n,int r) {
		long res = 1;
		long num = (fib[n] * ((long)((long)r+1L))) % mod;
		res = (long)(num / fib[n-r]);
		return res;
	}
	
	public static void main(String[] args) {
		Scanner sc = new Scanner(System.in);
		int n = sc.nextInt();
		long prev = 1;
		if(n==1) {
			System.out.print(prev);
			return;
		}
		for(int i=2;i<=n;i++) {
			long ans = (1L + prev + (i-2)*2)%mod;
			int n1 = (i+1)/2;
			n1 = n1 - 1;
			for(int j=2;j<=n1;j++) {
				ans = (ans + (comb(n1,j)%mod))%mod;
			}
			prev = ans;
		}
		System.out.println(prev);
	}
-----------------------------------------------------------------------------------------------------------------------------
public static String convert(String A, int B) {
        int i = 0;
        int n = A.length();
        if(n<=2 || B <=1){
            return A;
        }
        int b = B;
        StringBuilder sb = new StringBuilder();
        while(i<B){
            int index = i;
            while(index<n){
            	if(b==B) {
            		index += ((b-2) * 2) + 2;
            		if(index<n) sb.append(A.charAt(index));
            	}
            	else if(b==0) {
            		index += ((B-2) * 2) + 2;
            		if(index<n) sb.append(A.charAt(index));
            	}
            	else {
            		index+= ((b-2)*2) + 2;
            		if(index<n) sb.append(A.charAt(index));
            		index += ((B-2) * 2) + 2;
            		if(index<n) sb.append(A.charAt(index));
            	}
            }
            b--;
            i++;
        }
        return sb.toString();
    }

